<img src="https://hackernoon.com/banner-image.png" alt="drawing" width="1012"/>

# [data-engineering](https://hackernoon.com/tagged/data-engineering)
### [1. Introduction to a Career in Data Engineering](https://hackernoon.com/introduction-to-a-career-in-data-engineering)
![](https://cdn.hackernoon.com/images/lo4HVoscl4cgeiMrC6BRRx9HbrR2-kf037i5.jpeg)
A valuable asset for anyone looking to break into the Data Engineering field is understanding the different types of data and the Data Pipeline.

### [2. 5 Ways to Become a Leader That Data Engineers Will Love ](https://hackernoon.com/5-ways-to-become-a-leader-that-data-engineers-will-love)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-2va34zf.jpeg)
How to become a better data leader that the data engineers love?

### [3. Meet The Entrepreneur: Alon Lev, CEO, Qwak](https://hackernoon.com/meet-the-entrepreneur-alon-lev-ceo-qwak)
![](https://cdn.hackernoon.com/images/uwdds9GP9oRGK8rZBtabE59fB8P2-v393pac.jpeg)
Meet The Entrepreneur: Alon Lev, CEO, Qwak

### [4. Introduction to Great Expectations, an Open Source Data Science Tool](https://hackernoon.com/introduction-to-great-expectations-an-open-source-data-science-tool-8u353u04)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F496ukHyoUvbAHPjt342s7IiAF933-9i133uvi.jpeg?alt=media&token=64c8b57f-0b9e-4846-9be6-fd6e61b9ae24)
This is the first completed webinar of our “Great Expectations 101” series. The goal of this webinar is to show you what it takes to deploy and run Great Expectations successfully.

### [5. Is The Modern Data Warehouse Dead?](https://hackernoon.com/is-the-modern-data-warehouse-dead)
![](https://cdn.hackernoon.com/images/yDiiZrP5VkgnvI5vdWkH3Sfer452-6va3q93.jpeg)
Do we need a radical new approach to data warehouse technology? An immutable data warehouse starts with the data consumer SLAs and pipes data in pre-modeled.

### [6. Crunching Large Datasets Made Fast and Easy: the Polars Library](https://hackernoon.com/crunching-large-datasets-made-fast-and-easy-the-polars-library)
![](https://cdn.hackernoon.com/images/jS4idHWutGQSZh1LhxPcBOKKbP93-yz03sno.jpeg)
Processing large data, e.g. for cleansing, aggregation or filtering is done blazingly fast with the Polars data frame library in python thanks to its design.

### [7. How to Improve Query Speed to Make the Most out of Your Data](https://hackernoon.com/how-to-improve-query-speed-to-make-the-most-out-of-your-data)
![](https://cdn.hackernoon.com/images/S7yvVxnEjeVFhshvI3V9z5jwVy83-sya362u.jpeg)
In this article, I will talk about how I improved overall data processing efficiency by optimizing the choice and usage of data warehouses.

### [8. Can Your Organization's Data Ever Really Be Self-Service?](https://hackernoon.com/can-your-organizations-data-ever-really-be-self-service)
![](https://cdn.hackernoon.com/images/yDiiZrP5VkgnvI5vdWkH3Sfer452-3ma3opm.jpeg)
Self-serve systems are a big priority for data leaders, but what exactly does it mean? And is it more trouble than it's worth?

### [9. Solving Noom's Data Analyst Interview Questions](https://hackernoon.com/solving-nooms-data-analyst-interview-questions)
![](https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-3792bn1.jpeg)
Noom helps you lose weight. We help you get a job at Noom. In today’s article, we’ll show you one of Noom’s hard SQL interview questions.

### [10. Data Engineering Tools for Geospatial Data](https://hackernoon.com/data-engineering-tools-for-geospatial-data)
![](https://cdn.hackernoon.com/images/h21pEbL8NnPBgty9YVwf9GAvTuM2-jc93op7.jpeg)
Location-based information makes the field of geospatial analytics so popular today. Collecting useful data requires some unique tools covered in this blog.

### [11. Towards Open Options Chains - Part III: Get Started with Airflow](https://hackernoon.com/towards-open-options-chains-part-iii-getting-started-with-airflow)
![](https://cdn.hackernoon.com/images/U5RJ3dAJBFVRi8tZMrvpUnL7GE02-su03a59.jpeg)
In "Towards Open Options Chains", Chris Chow presents his solution for collecting options data: a data pipeline with Airflow, PostgreSQL, and Docker. 

### [12. Cost Effective Data Warehousing: Delta View and Partitioned Raw Table](https://hackernoon.com/cost-effective-data-warehousing-delta-view-and-partitioned-raw-table)
![](https://cdn.hackernoon.com/images/Ipw9RDLzC7fi7WOuDkympDfWmXy1-2c2352t.jpeg)
The worst nightmare of analytics managers is accidentally blowing up the data warehouse cost. How can we avoid receiving unexpectedly expensive bills?

### [13. How Datadog Revealed Hidden AWS Performance Problems](https://hackernoon.com/how-datadog-revealed-hidden-aws-performance-problems)
![](https://cdn.hackernoon.com/images/Py6qpufBR8M10yx90A1MjweyrbV2-7ua3qzh.png)
Migrating from Convox to Nomad and some AWS performance issues we encountered along the way thanks to Datadog

### [14. How We Use dbt (Client) In Our Data Team](https://hackernoon.com/how-we-use-dbt-client-in-our-data-engineering-team)
![](https://cdn.hackernoon.com/images/hQ9XDYVh65eL33xrAdSC2WRwOyk1-oj93h3o.jpeg)
Here is not really an article, but more some notes about how we use dbt in our team. 

### [15. How to Scrape NLP Datasets From Youtube](https://hackernoon.com/how-to-scrape-nlp-datasets-from-youtube)
![](https://cdn.hackernoon.com/images/DUgalx4alqOf4QlthE3dDI1x7Wq2-vqfx37hd.jpeg)
Too lazy to scrape nlp data yourself? In this post, I’ll show you a quick way to scrape NLP datasets using Youtube and Python.

### [16. Writing Pandas to Make Your Python Code Scale](https://hackernoon.com/writing-pandas-to-make-your-python-code-scale)
![](https://cdn.hackernoon.com/images/uIp8kazjiidZ9X18HxuOMLSVtjb2-qn934ur.jpeg)
Write efficient and flexible data-pipelines in Python that generalise to changing requirements.

### [17. Python & Data Engineering: Under the Hood of Join Operators ](https://hackernoon.com/python-and-data-engineering-under-the-hood-of-join-operators)
![](https://cdn.hackernoon.com/images/ARCWTrgYpoc531106B2eMedWoT42-djh35i5.jpeg)
In this post, I discuss the algorithms of a nested loop, hash join, and merge join in Python.

### [18. Smartype Hubs: Keeping Developers in Sync With Your Data Plan](https://hackernoon.com/smartype-hubs-keeping-developers-in-sync-with-your-data-plan)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-p6b3hrh.jpeg)
Implementing tracking code based on an outdated version of your organization's data plan can result in time-consuming debugging, dirty data pipelines, an

### [19. How to Setup Your Organisation's Data Team for Success](https://hackernoon.com/how-to-build-the-right-data-team-structure-for-your-organization)
![](https://cdn.hackernoon.com/images/yDiiZrP5VkgnvI5vdWkH3Sfer452-6l93k5f.jpeg)
Best practices for building a data team at a hypergrowth startup, from hiring your first data engineer to IPO. 

### [20. What Is A Data Mesh — And Is It Right For Me?](https://hackernoon.com/what-is-a-data-mesh-and-is-it-right-for-me)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-mna34vk.jpeg)
Ask anyone in the data industry what’s hot and chances are “data mesh” will rise to the top of the list. But what is a data mesh and is it right for you?

### [21. Data Teams Need Better KPIs. Here's How. ](https://hackernoon.com/data-teams-need-better-kpis-heres-how)
![](https://cdn.hackernoon.com/images/yDiiZrP5VkgnvI5vdWkH3Sfer452-1393ocx.jpeg)
Here are six important steps for setting goals for data teams. 

### [22. How To Create a Python Data Engineering Project with a Pipeline Pattern](https://hackernoon.com/how-to-create-a-python-data-engineering-project-with-a-pipeline-pattern-uj5t33od)
![](https://cdn.hackernoon.com/images/Apj3GcI7SYbhNozR0srJR5un7bT2-se7y33vo.jpeg)
In this article, we cover how to use pipeline patterns in python data engineering projects. Create a functional pipeline, install fastcore, and other steps.

### [23. Data Observability that Fits Any Data Team’s Structure](https://hackernoon.com/data-observability-that-fits-any-data-teams-structure)
![](https://cdn.hackernoon.com/images/QS5iLJhRSPR2YH4y0tLF8pVa75h1-3993ndi.jpeg)
Data teams come in all different shapes and sizes. How do you build data observability into your pipeline in a way that suits your team structure? Read on.

### [24. How to Build a Directed Acyclic Graph (DAG) - Towards Open Options Chains Part IV](https://hackernoon.com/how-to-build-a-directed-acyclic-graph-dag-towards-open-options-chains-part-iv)
![](https://cdn.hackernoon.com/images/U5RJ3dAJBFVRi8tZMrvpUnL7GE02-mya3gsh.jpeg)
In "Towards Open Options Chains", Chris Chow presents his solution for collecting options data: a data pipeline with Airflow, PostgreSQL, and Docker. 

### [25. 10 Key Skills Every Data Engineer Needs](https://hackernoon.com/10-key-skills-every-data-engineer-needs-x6273wad)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2Fx1Ku1ZlX5gS54YvjpjlUfUUePZw1-weq3tzl.jpeg?alt=media&token=259c96ff-8607-4b38-b4a6-8f8d0caf3b58)
Bridging the gap between Application Developers and Data Scientists, the demand for Data Engineers rose up to 50% in 2020, especially due to increase in investments in AI-based SaaS products.

### [26. What is a Data Reliability Engineer?](https://hackernoon.com/what-is-a-data-reliability-engineer)
![](https://cdn.hackernoon.com/images/M6G22rxQzLTqx37eMqcSVG1Ybvj2-ci93v4o.jpeg)
With each day, enterprises increasingly rely on data to make decisions. 

### [27. A Brief Introduction to 5 Predictive Models in Data Science](https://hackernoon.com/a-brief-introduction-to-5-predictive-models-in-data-science-252a338h)
![](https://cdn.hackernoon.com/images/8qL82uOvbngFBTtXaoUGORAStWY2-ij3n32es.jpeg)
Predictive Modeling in Data Science is more like the answer to the question “What is going to happen in the future, based on known past behaviors?”

### [28. 80% of Issues Aren't Caught by Testing Alone: Build Your Data Reliability Stack to Reduce Downtime](https://hackernoon.com/80percent-of-issues-arent-caught-by-testing-alone-build-your-data-reliability-stack-to-reduce-downtime)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-yg934x2.jpeg)
After speaking to hundreds of teams, I discovered ~80% of data issues aren’t covered by testing alone. Here are 4 layers to building a data reliability stack.

### [29. Cloud Services Will Take Over the World, says Noonies Nominee and Python Teacher, Veronika](https://hackernoon.com/cloud-services-will-take-over-the-world-says-noonies-nominee-and-python-teacher-veronika)
![](https://cdn.hackernoon.com/images/7KcY1Ek526RZcA1svArWnEHsDFg1-lz036xf.jpeg)
2021 Noonies Nominee General Interview with Veronika. Read for more on cloud services, data engineering, and python.

### [30. Getting Information From The Most Granular Demographics Dataset](https://hackernoon.com/getting-information-from-the-most-granular-demographics-dataset-8b2u348v)
![](https://cdn.hackernoon.com/images/eoFt9fvUnJZWjIQFjCu3guaNGFj2-wl3q2a4c.gif)
Find out how to set up and work locally with the most granular demographics dataset that is out there.

### [31. How to Build Machine Learning Algorithms that Actually Work](https://hackernoon.com/how-to-build-machine-learning-algorithms-that-actually-work)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-pya349p.jpeg)
Applying machine learning models at scale in production can be hard. Here's the four biggest challenges data teams face and how to solve them.

### [32. An 80% Reduction in Standard Audience Calculation Time](https://hackernoon.com/how-we-reduced-standard-audience-calculation-time-by-80percent)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-2t93nfd.png)
Standard Audiences: A product that extends the functionality of regular Audiences, one of the most flexible, powerful, and heavily leveraged tools on mParticle.

### [33. Six Habits to Adopt for Highly Effective Data](https://hackernoon.com/six-habits-to-adopt-for-highly-effective-data)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-dw237c6.jpeg)
Put your organization on the path to consistent data quality with by adopting these six habits of highly effective data.

### [34. Certify Your Data Assets to Avoid Treating Your Data Engineers Like Catalogs](https://hackernoon.com/certify-your-data-assets-to-avoid-treating-your-data-engineers-like-catalogs)
![](https://cdn.hackernoon.com/images/yDiiZrP5VkgnvI5vdWkH3Sfer452-a2b3nfb.jpeg)
Data trust starts and ends with communication. Here’s how best-in-class data teams are certifying tables as approved for use across their organization.

### [35. Introduction To Amazon SageMaker](https://hackernoon.com/introduction-to-amazon-sagemaker-7b1t3ujb)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F7ak2yVPeR1U2jfyp58b4NnJvnq03-v51y3ul6.jpeg?alt=media&token=bc9a8cb9-dc34-4a41-b152-6f35d78d2509)
Amazon AI/ML Stack

### [36. 4 Critical Steps To Build A Large Catalog Of Connectors Remarkably Well](https://hackernoon.com/4-critical-steps-to-build-a-large-catalog-of-connectors-remarkably-well-o5113whl)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FrGWF1RDlLZchb3zju0HpnW7gT6X2-yo1n3wel.jpeg?alt=media&token=613e6f3e-342f-4942-9555-4de6608c0076)
The art of building a large catalog of connectors is thinking in onion layers.

### [37. Machine-Learning Neural Spatiotemporal Signal Processing with PyTorch Geometric Temporal](https://hackernoon.com/machine-learning-neural-spatiotemporal-signal-processing-with-pytorch-geometric-temporal-u84a338k)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F9Gxjkg9T2jXXyUUxsVXTFtCtsz62-y62i204b.jpeg?alt=media&token=dfa4112e-aaef-47b5-b6db-e932acb91cbe)
PyTorch Geometric Temporal is a deep learning library for neural spatiotemporal signal processing.

### [38. Serving Structured Data in Alluxio: Example](https://hackernoon.com/serving-structured-data-in-alluxio-example-653w3yfr)
![](https://cdn.filestackcontent.com/6rXasLNJQrCF1wsIGp8Q)
In the previous article, I described the concept and design of the Structured Data Service in the Alluxio 2.1.0 release. This article will go through an example to demonstrate how it helps SQL and structured data workloads.

### [39. Towards Open Options Chains: 
A Data Pipeline Solution - Part I](https://hackernoon.com/towards-open-options-chains-a-data-pipeline-solution-for-options-data-part-i)
![](https://cdn.hackernoon.com/images/U5RJ3dAJBFVRi8tZMrvpUnL7GE02-kd3393c.jpeg)
In "Towards Open Options Chains", Chris Chow presents his solution for collecting options data: a data pipeline with Airflow, PostgreSQL, and Docker.

### [40. Why Businesses Need Data Governance](https://hackernoon.com/why-businesses-need-data-governance)
![](https://cdn.hackernoon.com/images/oq0POZv7R3eyDbybW9s9FgRaNw33-un53517.png)
Governance is the Gordian Knot to all Your Business Problems.

### [41. Best Types of Data Visualization](https://hackernoon.com/best-types-of-data-visualization)
![](https://cdn.hackernoon.com/images/3pmZOmwsmTO9E2NpCze2AdxOMkH2-uw93onz.jpeg)
Learning about best data visualisation tools may be the first step in utilising data analytics to your advantage and the benefit of your company

### [42. Serving Structured Data in Alluxio: Example](https://hackernoon.com/serving-structured-data-in-alluxio-example-l1193y6c)
![](https://cdn.filestackcontent.com/6rXasLNJQrCF1wsIGp8Q)
In the previous article, I described the concept and design of the Structured Data Service in the Alluxio 2.1.0 release. This article will go through an example to demonstrate how it helps SQL and structured data workloads.

### [43. Data Engineering Hack: Using CDPs for Simplified Data Collection](https://hackernoon.com/data-engineering-hack-using-cdps-for-simplified-data-collection)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-qvce35gm.jpeg)
From simplifying data collection to enabling data-driven feature development, Customer Data Platforms (CDPs) have far-reaching value for engineers. 

### [44. Build vs Buy: What We Learned by Implementing a Data Catalog](https://hackernoon.com/build-vs-buy-what-we-learned-by-implementing-a-data-catalog-7b38377h)
![](https://cdn.hackernoon.com/images/PmrIjkNZdRSPeMkzaudjCz4ECqR2-g52629i4.jpeg)
Why we chose to finally buy a unified data workspace (Atlan), after spending 1.5 years building our own internal solution with Amundsen and Atlas

### [45. Apache Airflow: Is It a Good Tool for Data Quality Checks?](https://hackernoon.com/apache-airflow-is-it-a-good-tool-for-data-quality-checks)
![](https://cdn.hackernoon.com/images/Vd9vRm9WAwROtFEwhFqn42j2hI73-18b3p6r.jpeg)
Learn the impact of airflow on the data quality checks and why you should look for an alternative solution tool

### [46. Towards Open Options Chains Part V: Containerizing the Pipeline](https://hackernoon.com/towards-open-options-chains-part-v-containerizing-the-pipeline)
![](https://cdn.hackernoon.com/images/U5RJ3dAJBFVRi8tZMrvpUnL7GE02-ro93g5a.jpeg)
In "Towards Open Options Chains", Chris Chow presents his solution for collecting options data: a data pipeline with Airflow, PostgreSQL, and Docker. 

### [47. Docker Dev Workflow for Apache Spark](https://hackernoon.com/docker-dev-workflow-for-apache-spark-c91i3zt1)
![](https://cdn.hackernoon.com/images/HXPZ3GXgbYYvxF7Nq1wFE6LXU8q1-4p5v3wpe.png)
The benefits that come with using Docker containers are well known: they provide consistent and isolated environments so that applications can be deployed anywhere - locally, in dev / testing / prod environments, across all cloud providers, and on-premise - in a repeatable way. 

### [48. The Advantages of a Hybrid Deployment Architecture ](https://hackernoon.com/the-advantages-of-a-hybrid-deployment-architecture)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-gcc34iq.png)
See how a hybrid architecture marries the best of the SaaS world and on-prem world for modern data stack software.

### [49. Influenza Vaccines: The Data Science Behind Them](https://hackernoon.com/influenza-vaccines-the-data-science-behind-them-mpfn3yux)
![](https://images.unsplash.com/photo-1578307985320-34b61a66c195?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjEwMDk2Mn0)
Influenza Vaccines and Data Science in Biology

### [50. 5 Most Important Tips Every Data Analyst Should Know](https://hackernoon.com/5-most-important-tips-every-data-analyst-should-know)
![](https://cdn.hackernoon.com/images/oq0POZv7R3eyDbybW9s9FgRaNw33-br037ps.png)
The 5 things every data analyst should know and why it is not Python, nor SQL


### [51. Scale Your Data Pipelines with Airflow and Kubernetes](https://hackernoon.com/scale-your-data-pipelines-with-airflow-and-kubernetes-go7r3y85)
![](https://cdn.hackernoon.com/images/b01293y07.jpg)
It doesn’t matter if you are running background tasks, preprocessing jobs or ML pipelines. Writing tasks is the easy part. The hard part is the orchestration— Managing dependencies among tasks, scheduling workflows and monitor their execution is tedious.

### [52. The Growth Marketing Writing Contest by mParticle and HackerNoon](https://hackernoon.com/the-growth-marketing-writing-contest-by-mpartical-and-hackernoon)
![](https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-fc93pb1.jpeg)
mParticle & HackerNoon are excited to host a Growth Marketing Writing Contest. Here’s your chance to win money from a whopping $12,000 prize pool!

### [53. The DeltaLog: Fundamentals of Delta Lake [Part 2]](https://hackernoon.com/the-deltalog-fundamentals-of-delta-lake-part-2-nu2933fm)
![](https://cdn.hackernoon.com/images/QFJM4eCYV0YfKqZEqQvp0RuUgKl2-1a2x3386.jpeg)
Multi-part series that will take you from beginner to expert in Delta Lake

### [54. A Guide to Implementing an mParticle Data Plan in an eCommerce App](https://hackernoon.com/a-guide-to-implementing-an-mparticle-data-plan-in-an-ecommerce-app)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-ok43724.png)
See mParticle data events and attributes displayed in an eCommerce UI, and experiment with implementing an mParticle data plan yourself.

### [55. HarperDB is More Than Just a Database: Here's Why](https://hackernoon.com/harperdb-is-more-than-just-a-database-heres-why-972h371l)
![](https://cdn.hackernoon.com/images/W8O8r27oUwUryhNHNMOvKfQBLNn2-vbs357k.jpeg)
HarperDB is more than just a database, and for certain users or projects, HarperDB is not serving as a database at all. How can this be possible?

### [56. Why Microservices Suck At Machine Learning...and What You Can Do About It](https://hackernoon.com/why-microservices-suck-for-machine-learningand-what-you-can-do-about-it-1te2326t)
![](https://images.unsplash.com/photo-1545987796-200677ee1011?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjEwMDk2Mn0)
I've worked on teams building ML-powered product features, everything from personalization to propensity paywalls. Meetings to find and get access to data consumed my time, other days it was consumed building ETLs to get and clean that data. The worst situations were when I had to deal with existing microservice oriented architectures. I wouldn't advocate that we stop using microservices, but if you want to fit in a ML project in an already in-place strict microservice oriented architecture, you're doomed.

### [57. How We Improved Spark Jobs on HDFS Up To 30 Times](https://hackernoon.com/how-we-improved-spark-jobs-on-hdfs-up-to-30-times-ps313uaq)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FMEO1Whp7pdbY2Fmqr6xMgItyqS23-a2kn3ugt.jpeg?alt=media&token=f0842e70-f75e-4ac7-a37b-b7651e3ea90a)
As the third largest e-commerce site in China, Vipshop processes large amounts of data collected daily to generate targeted advertisements for its consumers. In this article, guest author Gang Deng from Vipshop describes how to meet SLAs by improving struggling Spark jobs on HDFS by up to 30x, and optimize hot data access with Alluxio to create a reliable and stable computation pipeline for e-commerce targeted advertising. 

### [58. Using Data Aggregation to Understand Cost of Goods Sold](https://hackernoon.com/using-data-aggregation-to-understand-cost-of-goods-sold)
![](https://cdn.hackernoon.com/images/adxOC8WlP1OTnFqCw6rgfMcBzQI2-63e2ikt.png)
This case study describes how we built a custom library that combines data housed in disparate sources to acquire the insights we needed.

### [59. Why Data Science is a Team Sport?](https://hackernoon.com/why-data-science-is-a-team-sport-s9103ugb)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F1XqttlSF7QQqgHUI82pViNNnBDt2-c81r3udc.jpeg?alt=media&token=409caa38-baf0-49b4-9095-fb8814ff4b7c)
Today, I am going to cover why I consider data science as a team sport?

### [60. Building a Large-Scale Interactive SQL Query Engine with Open Source Software](https://hackernoon.com/building-a-large-scale-interactive-sql-query-engine-with-open-source-software-ww2z3yf6)
![](https://cdn.hackernoon.com/drafts/xm1g3yfs.png)
This is a collaboration between Baolong Mao's team at JD.com and my team at Alluxio. The original article was published on Alluxio's blog. This article describes how JD built an interactive OLAP platform combining two open-source technologies: Presto and Alluxio.

### [61. Introducing Handoff: Serverless Data Pipeline Orchestration Framework](https://hackernoon.com/introducing-handoff-serverless-data-pipeline-orchestration-framework-z12q22an)
![](https://hackernoon.com/images/Ipw9RDLzC7fi7WOuDkympDfWmXy1-gt83455.jpeg)
handoff is a serverless data pipeline orchestration framework simplifies the process of deploying ETL/ELT tasks to AWS Fargate.

### [62. Are NoSQL databases relevant for data engineering?](https://hackernoon.com/are-nosql-databases-relevant-for-data-engineering-6f1y35zd)
![](https://cdn.hackernoon.com/images/JT4BgXlfxveziEP9szyBKsEXoFf2-8i2k33va.jpeg)
In this article, we’ll investigate use cases for which data engineers may need to interact with NoSQL database, as well as the pros and cons.

### [63. What is the Future of the Data Engineer? - 6 Industry Drivers](https://hackernoon.com/what-is-the-future-of-the-data-engineer-6-industry-drivers)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-umf3zom.jpeg)
Is the data engineer still the "worst seat at the table?" Maxime Beauchemin, creator of Apache Airflow and Apache Superset, weighs in. 

### [64. How DAGs Grow: When People Trust A Data Source, They'll Ask More Of It](https://hackernoon.com/how-dags-grow-when-people-trust-a-data-source-theyll-ask-more-of-it-eri3w65)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F496ukHyoUvbAHPjt342s7IiAF933-5co3wnl.jpeg?alt=media&token=da5f1789-b43b-4511-a986-526684d9692e)
This blog post is a refresh of a talk that James and I gave at Strata back in 2017. Why recap a 3-year-old conference talk? Well, the core ideas have aged well, we’ve never actually put them into writing before, and we’ve learned some new things in the meantime. Enjoy!

### [65. Towards Open Options Chains Part II: Foundational ETL Code](https://hackernoon.com/towards-open-options-chains-part-ii-foundational-etl-code)
![](https://cdn.hackernoon.com/images/U5RJ3dAJBFVRi8tZMrvpUnL7GE02-091362n.jpeg)
In "Towards Open Options Chains", Chris Chow presents his solution for collecting options data: a data pipeline with Airflow, PostgreSQL, and Docker. 

### [66. How We Built A Cross-Region Hybrid Cloud Storage Gateway for ML & AI at WeRide](https://hackernoon.com/how-we-built-a-cross-region-hybrid-cloud-storage-gateway-for-ml-and-ai-at-weride-3g1q3x1i)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FMEO1Whp7pdbY2Fmqr6xMgItyqS23-tm2l3upf.jpeg?alt=media&token=c3ba97a9-d99e-4d0d-b726-e97ef4ea6b0f)
In this blog, guest writer Derek Tan, Executive Director of Infra & Simulation at WeRide, describes how engineers leverage Alluxio as a hybrid cloud data gateway for applications on-premises to access public cloud storage like AWS S3. 

### [67. Introduction to Delight: Spark UI and Spark History Server](https://hackernoon.com/introduction-to-delight-spark-ui-and-spark-history-server-9b1w2409)
![](https://cdn.hackernoon.com/images/HXPZ3GXgbYYvxF7Nq1wFE6LXU8q1-qw934ju.jpeg)
Delight is an open-source an cross-platform monitoring dashboard for Apache Spark with memory & CPU metrics complementing the Spark UI and Spark History Server.

### [68. Want to Create Data Circuit Breakers with Airflow? Here's How!](https://hackernoon.com/want-to-create-data-circuit-breakers-with-airflow-heres-how)
![](https://cdn.hackernoon.com/images/DttJtZIouwez0hRqxMq7CdRoQP83-mt935ht.jpeg)
See how to leverage the Airflow ShortCircuitOperator to create data circuit breakers to prevent bad data from reaching your data pipelines.

### [69. How To Build An n8n Workflow To Manage Different Databases and Scheduling Workflows](https://hackernoon.com/how-to-build-an-n8n-workflow-to-manage-different-databases-and-scheduling-workflows-sq8h35ld)
![](https://cdn.hackernoon.com/images/zhuoO29JlJebgaxanq2fbxKNuEu1-5bw24dh.jpeg)
Learn how to build an n8n workflow that processes text, stores data in two databases, and sends messages to Slack.

### [70. Why Data Quality is Key to Successful ML Ops](https://hackernoon.com/why-data-quality-is-key-to-successful-ml-ops-e61v3tle)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F496ukHyoUvbAHPjt342s7IiAF933-l0203t8o.jpeg?alt=media&token=331e0060-ad1e-4b77-a2c9-d42abed58753)
In this first post in our 2-part ML Ops series, we are going to look at ML Ops and highlight how and why data quality is key to ML Ops workflows.

### [71. Save and Search Through Your Slack Channel History on a Free Slack Plan](https://hackernoon.com/save-and-search-through-your-slack-channel-history-on-a-free-slack-plan-136233hu)
![](https://cdn.hackernoon.com/images/rGWF1RDlLZchb3zju0HpnW7gT6X2-wl3b33vt.jpeg)
Sometimes, we might not be able to afford a paid subscription on Slack. Here's a tutorial on how you can save and search through your Slack history for free.

### [72. An Introduction to Data Connectors: Your First Step to Data Analytics](https://hackernoon.com/an-introduction-to-data-connectors-your-first-step-to-data-analytics-9g45331x)
![](https://cdn.hackernoon.com/images/mQxRtgkzCxTKq2Up5veXSbnzg4g1-4kgp330o.png)
This post explains what a data connector is and provides a framework for building connectors that replicate data from different sources into your data warehouse

### [73. Data Location Awareness: The Benefits of Implementing Tiered Locality](https://hackernoon.com/data-location-awareness-the-benefits-of-implementing-tiered-locality-tqb432zk)
![](https://cdn.hackernoon.com/drafts/e12ey3ybh.png)
Tiered Locality is a feature led by my colleague Andrew Audibert at Alluxio. This article dives into the details of how tiered locality helps provide optimized performance and lower costs. The original article was published on Alluxio’s engineering blog

### [74. 7 Gotchas(!) Data Engineers Need to Watch Out for in an ML Project](https://hackernoon.com/7-gotchas-data-engineers-need-to-watch-out-for-in-an-ml-project-ev6t33mx)
![](https://cdn.hackernoon.com/images/mt1ibdilsjNcDF11ceiEAGwT9663-gt4233yd.jpeg)
This article covers 7 data engineering gotchas in an ML project. The list is sorted in descending order based on the number of times I've encountered each one.

### [75. Build A Crypto Price Tracker using Node.js and Cassandra](https://hackernoon.com/build-a-crypto-price-tracker-using-nodejs-and-cassandra-7pn35oa)
![](https://cdn.hackernoon.com/images/yvAYLwH0XzSQ3fMrG8o677THSb62-hu1030xn.jpeg)
Since the big bang in the data technology landscape happened a decade and a half ago, giving rise to technologies like Hadoop, which cater to the four ‘V’s. — volume, variety, velocity, and veracity there has been an uptick in the use of databases with specialized capabilities to cater to different types of data and usage patterns. You can now see companies using graph databases, time-series databases, document databases, and others for different customer and internal workloads.

### [76. Serving Structured Data in Alluxio](https://hackernoon.com/serving-structured-data-in-alluxio-ov3o3y5y)
![](https://cdn.hackernoon.com/drafts/j01t33y2j.png)
This article introduces Structured Data Management (Developer Preview) available in the latest Alluxio 2.1.0 release, a new effort to provide further benefits to SQL and structured data workloads using Alluxio. The original concept was discussed on Alluxio’s engineering blog. This article is part one of the two articles on the Structured Data Management feature my team worked on. 

### [77. 9 Best Data Engineering Courses You Should Take in 2023](https://hackernoon.com/9-best-data-engineering-courses-you-should-take-in-2022)
![](https://cdn.hackernoon.com/images/BYWRsHWtmGOUC5N4fwNhMqohMAC3-gb93hlq.jpeg)
In this listicle, you'll find some of the best data engineering courses, and career paths that can help you jumpstart your data engineering journey!

### [78. Efficient Model Training in the Cloud with Kubernetes, TensorFlow, and Alluxio Open Source](https://hackernoon.com/efficient-model-training-in-the-cloud-with-kubernetes-tensorflow-and-alluxio-open-source-054530s3)
![](https://cdn.filestackcontent.com/YJ35GqIJQ6au2t7z7DaC)
This article presents the collaboration of Alibaba, Alluxio, and Nanjing University in tackling the problem of Deep Learning model training in the cloud. Various performance bottlenecks are analyzed with detailed optimizations of each component in the architecture. This content was previously published on Alluxio's Engineering Blog, featuring Alibaba Cloud Container Service Team's case study (White Paper here). Our goal was to reduce the cost and complexity of data access for Deep Learning training in a hybrid environment, which resulted in over 40% reduction in training time and cost.

### [79. Understanding the Differences between Data Science and Data Engineering ](https://hackernoon.com/understanding-the-differences-between-data-science-and-data-engineering)
![](https://cdn.hackernoon.com/images/k637U4fYr0RGVspCP5s7dpkuIBG2-8v93d32.jpeg)
A brief description of the difference between Data Science and Data Engineering.

### [80. Everything You Need to Know About Deep Data Observability](https://hackernoon.com/everything-you-need-to-know-about-deep-data-observability)
![](https://cdn.hackernoon.com/images/3XLgsHTm1aUbNjFahZSFn2SkeT03-b7c36vn.jpeg)
What's Deep Data Observability and how it's different from Shallow.

### [81. How To Productionalize ML By Development Of Pipelines Since The Beginning](https://hackernoon.com/how-to-productionalize-ml-by-development-of-pipelines-since-the-beginning-64o33zp)
![](https://cdn.hackernoon.com/images/sqm3y2RrpCOJ4vEb1zhSXrxAev23-guag33sv.jpeg)
Writing ML code as pipelines from the get-go reduces technical debt and increases velocity of getting ML in production.

### [82. Data Testing: It's About Both Problem Detection and Quality of Response](https://hackernoon.com/data-testing-its-about-both-problem-detection-and-quality-of-response-r34c3wcx)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F496ukHyoUvbAHPjt342s7IiAF933-6d53wit.jpeg?alt=media&token=7a3e4df4-0f6c-4375-8beb-660139f8a3a2)
Congratulations, you’ve successfully implemented data testing in your pipeline! 

### [83. How Machine Learning is Used in Astronomy](https://hackernoon.com/how-machine-learning-used-in-astronomy-g4d73yot)
![](https://cdn.hackernoon.com/drafts/4x543y95.png)
Is Astronomy data science?

### [84. How To Deploy Metabase on Google Cloud Platform (GCP)?](https://hackernoon.com/how-to-deploy-metabase-on-google-cloud-platform-gcp-ixv3xpo)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FJ2f6pmbeC6ZHpcyxfhCWKBuMpi33-pk5j3ufs.jpeg?alt=media&token=6573682d-4763-4b66-b7a6-ddbfd946316f)
Metabase is a business intelligence tool for your organisation that plugs in various data-sources so you can explore data and build dashboards. I'll aim to provide a series of articles on provisioning and building this out for your organisation.  This article is about getting up and running quickly.

### [85. Performance Benchmark: Apache Spark on DataProc Vs. Google BigQuery](https://hackernoon.com/performance-benchmark-apache-spark-on-dataproc-vs-google-bigquery-5l3w3ur5)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2F3nhao37bBEfHA9RTQ0WNVWfXPD02-bi383uct.gif?alt=media&token=dbf4e022-0bbc-423e-b192-f945f78c2f8d)

When it comes to Big Data infrastructure on Google Cloud Platform , the most popular choices Data architects need to consider today are Google BigQuery – A serverless, highly scalable and cost-effective cloud data warehouse, Apache Beam based Cloud Dataflow and Dataproc – a fully managed cloud service for running Apache Spark and Apache Hadoop clusters in a simpler, more cost-efficient way.

### [86. Deep Learning at Alibaba Cloud with Alluxio: How To Run PyTorch on HDFS](https://hackernoon.com/deep-learning-at-alibaba-cloud-with-alluxio-how-to-run-pytorch-on-hdfs-nep3uhm)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FMEO1Whp7pdbY2Fmqr6xMgItyqS23-pkao3u67.webp?alt=media&token=ac759dff-1842-4e24-9696-86d3fe1f1bbc)
This tutorial shows how Alibaba Cloud Container team runs PyTorch on HDFS using Alluxio under Kubernetes environment. The original Chinese article was published on Alibaba Cloud's engineering blog, then translated and published on Alluxio's Engineering Blog 

### [87. Running Presto Engine in a Hybrid Cloud Architecture](https://hackernoon.com/running-presto-engine-in-a-hybrid-cloud-architecture-3vq3ujy)
![](https://firebasestorage.googleapis.com/v0/b/hackernoon-app.appspot.com/o/images%2FMEO1Whp7pdbY2Fmqr6xMgItyqS23-4e4i3uot.jpeg?alt=media&token=2a0e1557-8b0e-4493-afb7-214e9f570636)
Migrating Presto workloads from a fully on-premise environment to cloud infrastructure has numerous benefits, including alleviating resource contention and reducing costs by paying for computation resources on an on-demand basis. In the case of Presto running on data stored in HDFS, the separation of compute in the cloud and storage on-premises is apparent since Presto’s architecture enables the storage and compute components to operate independently. The critical issue in this hybrid environment of Presto in the cloud retrieving HDFS data from an on-premise environment is the network latency between the two clusters.

### [88. Database Tips: 7 Reasons Why Data Lakes Could Solve Your Problems](https://hackernoon.com/database-tips-7-reasons-why-data-lakes-could-solve-your-problems-sf6g339c)
![](https://cdn.hackernoon.com/images/JT4BgXlfxveziEP9szyBKsEXoFf2-gi3w345w.jpeg)
Data lakes are an essential component in building any future-proof data platform. In this article, we round up 7 reasons why you need a data lake. 

### [89. Why Are We Teaching Pandas Instead of SQL?](https://hackernoon.com/why-are-we-teaching-pandas-instead-of-sql)
![](https://cdn.hackernoon.com/images/M6G22rxQzLTqx37eMqcSVG1Ybvj2-bna3vw9.jpeg)
How I learned to stop using pandas and love SQL. 

### [90. How to Build a Data Stack from Scratch](https://hackernoon.com/how-to-build-a-data-stack-from-scratch-v91a37qc)
![](https://cdn.hackernoon.com/images/oq0POZv7R3eyDbybW9s9FgRaNw33-5248356n.png)
Overview of the modern data stack after interview 200+ data leaders. Decision Matrix for Benchmark (DW, ETL, Governance, Visualisation, Documentation, etc)

### [91. Power-up: Machine Learning and Data Engineering (R)evolution for Optimizing Marketing Efforts](https://hackernoon.com/power-up-machine-learning-and-data-engineering-revolution-for-optimizing-marketing-efforts)
![](https://cdn.hackernoon.com/images/machine-learning-and-data-engineering-cldh20tlo000101s6ebw7fphs.png)
This blog covers real-world use cases of businesses embracing machine learning and data engineering revolution to optimize their marketing efforts.

### [92. Event-Driven Change Data Capture: Introduction, Use Cases, and Tools](https://hackernoon.com/event-driven-change-data-capture-introduction-use-cases-and-tools-ef4433v4)
![](https://cdn.hackernoon.com/images/IV0JQLsMeUPtnTkzLruhJAkpC5F2-ki5z32nt.jpeg)
How to detect, capture, and propagate changes in source databases to target systems in a real-time, event-driven manner with Change Data Capture (CDC).

### [93. Goldman Sachs, Data Lineage, and Harry Potter Spells ](https://hackernoon.com/08252019-bmbv3r8d)
![](https://cdn.hackernoon.com/drafts/17ay3r3g.png)
Goldman Will Dominate Consumer Banking

### [94. Top 6 CI/CD Practices for End-to-End Development Pipelines](https://hackernoon.com/top-6-cicd-practices-for-end-to-end-development-pipelines-ca2833lx)
![](https://cdn.hackernoon.com/images/Q6jqYNh4CWONXyOitjdyRhKtVfx2-u0hr3f7c.jpeg)
Maximizing efficiency is about knowing how the data science puzzles fit together and then executing them.

### [95. How to Get Started with Data Version Control (DVC)](https://hackernoon.com/how-to-get-started-with-data-version-control-dvc-nn2n31bo)
![](https://cdn.hackernoon.com/images/RgWOTEIKFjaPmuk0FKWfkuoejiA2-ag9o22ff.jpeg)
Data Version Control (DVC) is a data-focused version of Git. In fact, it’s almost exactly like Git in terms of features and workflows associated with it.

### [96. How to Perform Data Augmentation with Augly Library](https://hackernoon.com/how-to-perform-data-augmentation-with-augly-library-bn1f37y4)
![](https://cdn.hackernoon.com/images/zVaxL0LohRUpfDQhznRQ9z3y5tj1-hu13325w.jpeg)
Data augmentation is a technique used by practitioners to increase the data by creating modified data from the existing data.

